<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sizhe Li</title>
  
  <meta name="author" content="Sizhe Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sizhe (Lester) Li 李思哲</name>
              </p>
              <p>I am a third-year undergraduate student at the University of Rochester (URoch) majoring in Computer Science and Applied Mathematics. 
                 I am fortunate to work with <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a> at URoch and <a href="https://serre-lab.clps.brown.edu/person/thomas-serre/">Thomas Serre</a> at Brown.
              </p>
              <p>
                My current research focuses on:
                <ul>
                  <li style="list-style-type:square"><b>Multimodal Learning</b>: audio-visual video understanding</li>
                  <li style="list-style-type:square"><b>Medical Computer Vision</b>: histopathological cancer classification</li>
                </ul>
              </p>
              <p style="text-align:center">
                <a href="mailto:sli96@u.rochester.edu">Email</a> &nbsp/&nbsp
                <a href="data/sizhe_li_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=KfUuNDwAAAAJ&hl=en/">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/_lesterli/">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/lester0866/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile/profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile/profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <!-- <p> -->
                 <!-- <span class="highlight">highlighted</span>. -->
              <!-- </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/space_time_memory/Teaser_2x.png" alt="prl" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="">
                <papertitle>Space-Time Memory Network for Sounding Object Localization in Videos</papertitle>
              </a>
              <br>
              <strong>Sizhe Li</strong>, <a href="http://yapengtian.org/">Yapeng Tian</a>, <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a>
              <br>
              <em>Under Review</em>
              <br>
              <!-- <a href="data/BarronPRL2009.bib">bibtex</a> -->
              <p>Leveraging temporal synchronization and association within sight and sound is an essential step towards robust localization of sounding objects. To this end, we propose a space-time memory network for sounding object localization in videos.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/neurips_2020_molecular/Teaser.png" alt="prl" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1oNsBNPL1mSupmUIxQGojOskZjncYTmg2/preview">
                <papertitle>Learning to localize mutation in lung adenocarcinoma histopathology images</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=m89kEz8AAAAJ&hl=en">Sahar Shahamatdar<sup>*</sup></a>, <a href="https://moffitt.org/providers/daryoush-saeed-vafa/">Daryoush Saeed-Vafa<sup>*</sup></a>, <a href="https://scholar.google.com/citations?user=cXZlAuQAAAAJ&hl=en">Drew Linsley<sup>*</sup></a>, <strong>Sizhe Li</strong>, 
              <a href="https://vivo.brown.edu/display/sr33">Sohini Ramachandran<sup>+</sup></a>, <a href="https://serre-lab.clps.brown.edu/person/thomas-serre/">Thomas Serre<sup>+</sup></a> (Equal contribution<sup>*</sup>, Equal advising<sup>+</sup>)
              <br>
              <em>NeurIPS2020 LMRL Workshop</em>
              <br>
              <!-- <a href="data/BarronPRL2009.bib">bibtex</a> -->
              <p>Molecular profiling of cancers is necessary to identify the optimal therapeutic options for patients. However, these assays are time-and-resource-intensive to perform, and they cannot accurately capture mutational 
                heterogeneity. Here, we present a novel approach to address these issues.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/aua_2020/Teaser.png" alt="prl" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.auajournals.org/doi/abs/10.1097/JU.0000000000000954.01">
                <papertitle>A Deep Learning Algorithm for the Diagnosis and Gleason Grading of Whole Slide Images of Prostate Cancer Core Biopsies</papertitle>
              </a>
              <br>
              <a href="">Ohad Kott<sup>*</sup></a>, <strong>Sizhe Li<sup>*</sup></strong>, <a href="https://scholar.google.com/citations?user=cXZlAuQAAAAJ&hl=en">Drew Linsley</a>, <a href="">Ali Amin</a>, <a href="">Bora Golijanin</a>,
              <a href="">Dragan Golijanin</a>, <a href="https://serre-lab.clps.brown.edu/person/thomas-serre/">Thomas Serre</a>, <a href="https://www.dfhcc.harvard.edu/insider/member-detail/member/boris-gershman-md/">Boris Gershman</a>
              (Equal contribution<sup>*</sup>)
              <br>
              <em>The Journal of Urology, 2020</em>
              <br>
              <!-- <a href="data/BarronPRL2009.bib">bibtex</a> -->
              <p>Deep learning has shown promising early results in the diagnosis and grading of prostate cancer. However, training such algorithms typically requires a large amount of manually annotated training data. 
                To solve this issue, we developed a weakly supervised approach for the diagnosis and gleason grading of prostate core biopsies.</p>
            </td>
          </tr>

        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
                <br><br><br>
                <br>Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
